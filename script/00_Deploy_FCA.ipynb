{"cells":[{"cell_type":"markdown","source":["![FCA Logo](https://github.com/Pulsweb/FCA/blob/main/media/FCA.png?raw=true)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"eaf556bf-a2bf-4e00-af19-3865ec0c92d5"},{"cell_type":"markdown","source":["#### Welcome to FCA Deployment\n","\n","This notebook deployes the latest FCA version in the specified workspace. It works for initial deployment and for the upgrade process of FCA.\n","\n","**What is happening in this notebook?**\n"," - The notebook checks the two cloud connections for FCA (if initial deployment, connections will be created, otherwise check only)\n"," - It downloads the latest FCA src files from Github\n"," - It deploys/updates the Fabric items in the current workspace\n","\n","If you **update** your existing FCA workspace:\n","- After the notebooks has been executed, you are **done**\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3fed6147-755d-461a-8a56-75e6aaab935b"},{"cell_type":"code","source":["%pip install ms-fabric-cli"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":true},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7439a740-1fc5-4e3c-a47e-de324036912a"},{"cell_type":"markdown","source":["### Import of needed libaries"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}},"jp-MarkdownHeadingCollapsed":true},"id":"cbb77f4b-4cc8-49c6-83cd-231680a1d618"},{"cell_type":"code","source":["import subprocess\n","import os\n","import json\n","from zipfile import ZipFile \n","import shutil\n","import re\n","import requests\n","import zipfile\n","from io import BytesIO\n","import yaml\n","import sempy.fabric as fabric"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T13:56:19.4241213Z","session_start_time":null,"execution_start_time":"2025-07-21T13:56:19.4250726Z","execution_finish_time":"2025-07-21T13:56:23.6005699Z","parent_msg_id":"e73f9665-c2f7-4eb5-bc31-26d2328b10d3"}},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"414e6feb-ec15-4bb6-b111-5558df98fea0"},{"cell_type":"markdown","source":["## Download of source & config files\n","This part downloads all source and config files of FCA needed for the deployment into the ressources of the notebook"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}},"jp-MarkdownHeadingCollapsed":true},"id":"44471f8d-0f6f-4d86-9bef-20a0afccd13e"},{"cell_type":"code","source":["def download_folder_as_zip(repo_owner, repo_name, output_zip, branch=\"main\", folder_to_extract=\"src\",  remove_folder_prefix = \"\"):\n","    # Construct the URL for the GitHub API to download the repository as a zip file\n","    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/zipball/{branch}\"\n","    \n","    # Make a request to the GitHub API\n","    response = requests.get(url)\n","    response.raise_for_status()\n","    \n","    # Ensure the directory for the output zip file exists\n","    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n","    \n","    # Create a zip file in memory\n","    with zipfile.ZipFile(BytesIO(response.content)) as zipf:\n","        with zipfile.ZipFile(output_zip, 'w') as output_zipf:\n","            for file_info in zipf.infolist():\n","                parts = file_info.filename.split('/')\n","                if  re.sub(r'^.*?/', '/', file_info.filename).startswith(folder_to_extract): \n","                    # Extract only the specified folder\n","                    file_data = zipf.read(file_info.filename)\n","                    output_zipf.writestr(('/'.join(parts[1:]).replace(remove_folder_prefix, \"\")), file_data)\n","\n","def uncompress_zip_to_folder(zip_path, extract_to):\n","    # Ensure the directory for extraction exists\n","    os.makedirs(extract_to, exist_ok=True)\n","    \n","    # Uncompress all files from the zip into the specified folder\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","    \n","    # Delete the original zip file\n","    os.remove(zip_path)\n","\n","repo_owner = \"Pulsweb\"\n","repo_name = \"FCA\"\n","branch = \"main\"\n","\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/src/src.zip\", branch = branch, folder_to_extract= f\"/src\")\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/config/config.zip\", branch = branch, folder_to_extract= f\"/config\")\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/data/data.zip\", branch = branch, folder_to_extract= f\"/data\")\n","uncompress_zip_to_folder(zip_path = \"./builtin/config/config.zip\", extract_to= \"./builtin\")\n","uncompress_zip_to_folder(zip_path = \"./builtin/data/data.zip\", extract_to= \"./builtin\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T14:25:06.0682025Z","session_start_time":null,"execution_start_time":"2025-07-21T14:25:06.0690062Z","execution_finish_time":"2025-07-21T14:25:10.2771196Z","parent_msg_id":"baef1345-5ba2-43ef-bd7a-9135fc137d28"}},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"70bfa16b-c718-48d6-81b1-00f456ccc80d"},{"cell_type":"code","source":["base_path = './builtin/'\n","\n","deploy_order_path = os.path.join(base_path, 'config/deployment_order.json')\n","with open(deploy_order_path, 'r') as file:\n","        deployment_order = json.load(file)\n","\n","mapping_table=[]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T14:29:57.0142082Z","session_start_time":null,"execution_start_time":"2025-07-21T14:29:57.0150824Z","execution_finish_time":"2025-07-21T14:29:57.3864939Z","parent_msg_id":"c8443b2a-bfa4-43eb-a172-1b3059254a32"}},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"eeef159d-0f52-43a1-a895-5c3b293ffc61"},{"cell_type":"markdown","source":["## Definition of deployment functions"],"metadata":{"nteract":{"transient":{"deleting":false}},"jp-MarkdownHeadingCollapsed":true},"id":"dd4b4640-8237-433b-ac46-8986531f28ce"},{"cell_type":"code","source":["# Set environment parameters for Fabric CLI\n","token = notebookutils.credentials.getToken('pbi')\n","os.environ['FAB_TOKEN'] = token\n","os.environ['FAB_TOKEN_ONELAKE'] = token\n","\n","def run_fab_command( command, capture_output: bool = False, silently_continue: bool = False):\n","    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n","    if (not(silently_continue) and (result.returncode > 0 or result.stderr)):\n","       raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result.stderr}'\")    \n","    if (capture_output): \n","        output = result.stdout.strip()\n","        return output\n","\n","def fab_get_id(name):\n","    id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q id\" , capture_output = True, silently_continue= True)\n","    return(id)\n","\n","def get_id_by_name(name):\n","    for it in deployment_order:\n","        if it.get(\"name\") == name:\n","                return it.get(\"id\")\n","    return None\n","\n","\n","def copy_to_tmp(name):\n","    shutil.rmtree(\"./builtin/tmp\",  ignore_errors=True)\n","    path2zip = \"./builtin/src/src.zip\"\n","    with  ZipFile(path2zip) as archive:\n","        for file in archive.namelist():\n","            if file.startswith(f'src/{name}/'):\n","                archive.extract(file, './builtin/tmp')\n","    return(f\"./builtin/tmp/src/{name}\" )\n","\n","\n","def replace_ids_in_folder(folder_path, mapping_table):\n","    for root, _, files in os.walk(folder_path):\n","        for file_name in files:\n","            if file_name.endswith(('.py', '.json', '.pbir', '.platform', '.ipynb', '.tmdl')) and not file_name.endswith('report.json'):\n","                file_path = os.path.join(root, file_name)\n","                with open(file_path, 'r', encoding='utf-8') as file:\n","                    content = file.read()\n","                    for mapping in mapping_table:  \n","                        content = content.replace(mapping[\"old_id\"], mapping[\"new_id\"])\n","                with open(file_path, 'w', encoding='utf-8') as file:\n","                    file.write(content)\n","\n","def get_semantic_model_id(report_folder):\n","    definition_file = os.path.join(report_folder, 'definition.pbir')\n","    if os.path.exists(definition_file):\n","        with open(definition_file, 'r', encoding='utf-8') as file:\n","            content = json.load(file)\n","            semantic_model_id = content.get('datasetReference', {}).get('byConnection', {}).get('pbiModelDatabaseName')\n","            if semantic_model_id:\n","                return semantic_model_id\n","    return None\n","\n","def update_sm_connection_to_fca_lakehouse(semantic_model_folder):\n","    new_sm_db= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FCA.Lakehouse -q properties.sqlEndpointProperties.connectionString\", capture_output = True, silently_continue=True)\n","    new_lakehouse_sql_id= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FCA.Lakehouse -q properties.sqlEndpointProperties.id\", capture_output = True, silently_continue=True)\n","        \n","    expressions_file = os.path.join(semantic_model_folder, 'definition', 'expressions.tmdl')\n","    if os.path.exists(expressions_file):\n","        with open(expressions_file, 'r', encoding='utf-8') as file:\n","            content = file.read()\n","            match = re.search(r'Sql\\.Database\\(\"([^\"]+)\",\\s*\"([^\"]+)\"\\)', content)\n","            if match:\n","                old_sm_db, old_lakehouse_sql_id = match.group(1), match.group(2)\n","                content = content.replace(old_sm_db, new_sm_db).replace(old_lakehouse_sql_id, new_lakehouse_sql_id)\n","                with open(expressions_file, 'w', encoding='utf-8') as file:\n","                    file.write(content)\n","\n","\n","def update_report_definition( path): \n","    semantic_model_id = get_semantic_model_id(path)\n","    definition_path = os.path.join(path, \"definition.pbir\")\n","   \n","    with open(definition_path, \"r\", encoding=\"utf8\") as file:\n","        report_definition = json.load(file)\n","\n","    report_definition[\"datasetReference\"][\"byPath\"] = None\n","\n","    by_connection_obj = {\n","            \"connectionString\": None,\n","            \"pbiServiceModelId\": None,\n","            \"pbiModelVirtualServerName\": \"sobe_wowvirtualserver\",\n","            \"pbiModelDatabaseName\": semantic_model_id,\n","            \"name\": \"EntityDataSource\",\n","            \"connectionType\": \"pbiServiceXmlaStyleLive\",\n","        }\n","\n","    report_definition[\"datasetReference\"][\"byConnection\"] = by_connection_obj\n","\n","    with open(definition_path, \"w\") as file:\n","            json.dump(report_definition, file, indent=4)\n","\n","def print_color(text, state):\n","    red  = '\\033[91m'\n","    yellow = '\\033[93m'  \n","    green = '\\033[92m'   \n","    white = '\\033[0m'  \n","    if state == \"error\":\n","        print(red, text, white)\n","    elif state == \"warning\":\n","        print(yellow, text, white)\n","    elif state == \"success\":\n","        print(green, text, white)\n","    else:\n","        print(\"\", text)\n","\n"," "],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T14:31:36.1920149Z","session_start_time":null,"execution_start_time":"2025-07-21T14:31:36.1930389Z","execution_finish_time":"2025-07-21T14:31:36.5707249Z","parent_msg_id":"9ac3a233-623b-4bf6-aeab-49cbe0804bed"}},"metadata":{}}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3bba6a51-107d-4c10-9a41-5cb2a9e07c27"},{"cell_type":"markdown","source":["## Creation of connections"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e7a24f9d-acfc-41a4-ae24-772e5200f74a"},{"cell_type":"markdown","source":["## Get current Workspace\n","This cell gets the current workspace to deploy FCA automatically inside it"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}},"jp-MarkdownHeadingCollapsed":true},"id":"4473b6db-df34-4a72-bd1a-05d5ddefa78e"},{"cell_type":"code","source":["trg_workspace_id = fabric.get_notebook_workspace_id()\n","res = run_fab_command(f\"api -X get workspaces/{trg_workspace_id}\" , capture_output = True, silently_continue=True)\n","trg_workspace_name = json.loads(res)[\"text\"][\"displayName\"]\n","\n","print(f\"Current workspace: {trg_workspace_name}\")\n","print(f\"Current workspace ID: {trg_workspace_id}\")\n","\n","\n","mapping_table.append({ \"old_id\": get_id_by_name(\"Focus\"), \"new_id\": trg_workspace_id })\n","mapping_table.append({ \"old_id\": \"00000000-0000-0000-0000-000000000000\", \"new_id\": trg_workspace_id })"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T14:31:51.1867114Z","session_start_time":null,"execution_start_time":"2025-07-21T14:31:51.187526Z","execution_finish_time":"2025-07-21T14:31:52.5017396Z","parent_msg_id":"7e6b1815-26d3-45d2-9dd5-4c466664fbe6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Current workspace: FCA 2\nCurrent workspace ID: 52628e1a-77cf-4532-bfc0-8e4206103311\n"]}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7d54542c-1e34-434b-bada-d73fbe7c2535"},{"cell_type":"markdown","source":["## Deployment Logic\n","This part iterates through all the items, gets the respective source code, replaces all IDs dynamically and deploys the new item"],"metadata":{"nteract":{"transient":{"deleting":false}},"jp-MarkdownHeadingCollapsed":true},"id":"f8628a42-1d8a-4192-8e75-4754e626fede"},{"cell_type":"code","source":["exclude = [\"Focus\", 'Deploy_FCA']\n","\n","for it in deployment_order:\n","\n","    new_id = None\n","    \n","    name = it[\"name\"]\n","\n","    if name in exclude:\n","            continue\n","\n","    print(\"\")\n","    print(\"#############################################\")\n","    print(f\"Deploying {name}\")\n","\n","    # Copy and replace IDs in the item\n","    tmp_path = copy_to_tmp(name)\n","    replace_ids_in_folder(tmp_path, mapping_table)\n","\n","    cli_parameter = ''\n","    if \"Notebook\" in name:\n","        cli_parameter = cli_parameter + \" --format .ipynb\"\n","    elif \"Lakehouse\" in name:\n","        run_fab_command(f\"create /{trg_workspace_name}.Workspace/{name}\" , silently_continue=True )\n","        new_id = fab_get_id(name)\n","        mapping_table.append({ \"old_id\": get_id_by_name(name), \"new_id\": new_id })\n","        \n","        continue\n","    elif \"Report\" in name:\n","        update_report_definition(  tmp_path  )\n","    elif \"SemanticModel\" in name:\n","        update_sm_connection_to_fca_lakehouse(tmp_path)\n","    \n","    \n","    run_fab_command(f\"import  /{trg_workspace_name}.Workspace/{name} -i {tmp_path} -f {cli_parameter} \", silently_continue= True)\n","    new_id= fab_get_id(name)\n","    mapping_table.append({ \"old_id\": it[\"id\"], \"new_id\": new_id })\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"b3b6a88e-de38-4dbe-8ea0-fc190178010b","normalized_state":"finished","queued_time":"2025-07-21T14:32:35.8535675Z","session_start_time":null,"execution_start_time":"2025-07-21T14:32:35.8545626Z","execution_finish_time":"2025-07-21T14:33:48.9687102Z","parent_msg_id":"e388e200-6d6e-4a21-9f07-59b91fa75efb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n#############################################\nDeploying FCA.Lakehouse\nx create: [AlreadyExists] An item with the same name exists\n\n#############################################\nDeploying 01_Load_Focus.Notebook\nImporting './builtin/tmp/src/01_Load_Focus.Notebook' → '/FCA 2.Workspace/01_Load_Focus.Notebook'...\n* '01_Load_Focus.Notebook' imported\n\n#############################################\nDeploying Generate_Calendar_Table.Notebook\nImporting './builtin/tmp/src/Generate_Calendar_Table.Notebook' → '/FCA 2.Workspace/Generate_Calendar_Table.Notebook'...\n* 'Generate_Calendar_Table.Notebook' imported\n\n#############################################\nDeploying Lakehouse_Optimization.Notebook\nImporting './builtin/tmp/src/Lakehouse_Optimization.Notebook' → '/FCA 2.Workspace/Lakehouse_Optimization.Notebook'...\n* 'Lakehouse_Optimization.Notebook' imported\n\n#############################################\nDeploying 01_Load_Meters.Notebook\nImporting './builtin/tmp/src/01_Load_Meters.Notebook' → '/FCA 2.Workspace/01_Load_Meters.Notebook'...\n* '01_Load_Meters.Notebook' imported\n\n#############################################\nDeploying FCA_Core_SM.SemanticModel\nImporting './builtin/tmp/src/FCA_Core_SM.SemanticModel' → '/FCA 2.Workspace/FCA_Core_SM.SemanticModel'...\n* 'FCA_Core_SM.SemanticModel' imported\n\n#############################################\nDeploying FCA_Core_Report.Report\nImporting './builtin/tmp/src/FCA_Core_Report.Report' → '/FCA 2.Workspace/FCA_Core_Report.Report'...\n* 'FCA_Core_Report.Report' imported\n\n#############################################\nDeploying Load FCA E2E.DataPipeline\nImporting './builtin/tmp/src/Load FCA E2E.DataPipeline' → '/FCA 2.Workspace/Load FCA E2E.DataPipeline'...\n* 'Load FCA E2E.DataPipeline' imported\n"]}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"315ef8af-ff5a-4323-869c-7198e910c0bf"}],"metadata":{"kernel_info":{"jupyter_kernel_name":"python3.11","name":"jupyter"},"kernelspec":{"display_name":"Jupyter","language":"Jupyter","name":"jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":""}],"default_lakehouse":"","default_lakehouse_name":"","default_lakehouse_workspace_id":""}}},"nbformat":4,"nbformat_minor":5}