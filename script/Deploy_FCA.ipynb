{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fed6147-755d-461a-8a56-75e6aaab935b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Welcome to FCA Deployment\n",
    "\n",
    "This notebook deployes the latest FCA version in the specified workspace. It works for initial deployment and for the upgrade process of FCA.\n",
    "\n",
    "**End-to-end documenation on fabric-toolbox:**\n",
    "\n",
    "**What is happening in this notebook?**\n",
    " - The notebook checks the two cloud connections for FCA (if initial deployment, connections will be created, otherwise check only)\n",
    " - It downloads the latest FCA src files from Github\n",
    " - It deploys/updates the Fabric items in the current workspace\n",
    "\n",
    "**Next steps**\n",
    "- (Optional) Change connection names, only if needed\n",
    "- Run this notebook\n",
    "\n",
    "If you **deploy** FCA in this workspace at the **first time**:\n",
    "- Navigate to the cloud connections\n",
    "- Search under cloud connection for **fca fabric-service-api admin** and for **fca pbi-service-api admin** \n",
    "- Add the credentials of your service principal to these connections\n",
    "\n",
    "If you **update** your existing FCA workspace:\n",
    "- After the notebooks has been executed, you are **done**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7439a740-1fc5-4e3c-a47e-de324036912a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T12:50:38.3618338Z",
       "execution_start_time": "2025-07-16T12:50:31.2064841Z",
       "normalized_state": "finished",
       "parent_msg_id": "5b8590db-c142-4709-b586-46b046eb122e",
       "queued_time": "2025-07-16T12:50:28.0263903Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": "2025-07-16T12:50:28.0272138Z"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ms-fabric-cli\n",
      "  Downloading ms_fabric_cli-1.0.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: msal<2,>=1.29 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal[broker]<2,>=1.29->ms-fabric-cli) (1.32.0)\n",
      "Requirement already satisfied: msal_extensions in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.2.0)\n",
      "Collecting questionary (from ms-fabric-cli)\n",
      "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: prompt_toolkit>=3.0.41 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (3.0.50)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (5.5.2)\n",
      "Requirement already satisfied: jmespath in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.0.1)\n",
      "Requirement already satisfied: pyyaml==6.0.2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.32.3)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.8.0)\n",
      "Requirement already satisfied: cryptography<47,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (44.0.2)\n",
      "Requirement already satisfied: wcwidth in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from prompt_toolkit>=3.0.41->ms-fabric-cli) (0.2.13)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal_extensions->ms-fabric-cli) (2.10.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cryptography<47,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (1.17.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2024.7.4)\n",
      "Requirement already satisfied: pycparser in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography<47,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.22)\n",
      "Downloading ms_fabric_cli-1.0.1-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: questionary, ms-fabric-cli\n",
      "Successfully installed ms-fabric-cli-1.0.1 questionary-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ms-fabric-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e022b8-0d0d-4236-857c-6d253c78122d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-07T09:12:27.6584541Z",
       "execution_start_time": "2025-07-07T09:12:27.3502592Z",
       "normalized_state": "finished",
       "parent_msg_id": "67fef994-35ad-4acb-846c-2fc02c20c14e",
       "queued_time": "2025-07-07T09:12:18.4147169Z",
       "session_id": "11679e3a-08e5-4971-be9f-8a7922168e09",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##pbi_connection_name = 'fca pbi-service-api admin'\n",
    "##fabric_connection_name = 'fca fabric-service-api admin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb77f4b-4cc8-49c6-83cd-231680a1d618",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Import of needed libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414e6feb-ec15-4bb6-b111-5558df98fea0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T12:50:43.8631206Z",
       "execution_start_time": "2025-07-16T12:50:38.3630796Z",
       "normalized_state": "finished",
       "parent_msg_id": "38a59e25-710c-47d8-9e29-cf66295c73b7",
       "queued_time": "2025-07-16T12:50:34.282177Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile \n",
    "import shutil\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "import sempy.fabric as fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44471f8d-0f6f-4d86-9bef-20a0afccd13e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Download of source & config files\n",
    "This part downloads all source and config files of FUAM needed for the deployment into the ressources of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70bfa16b-c718-48d6-81b1-00f456ccc80d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T13:06:47.359621Z",
       "execution_start_time": "2025-07-16T13:06:43.1537029Z",
       "normalized_state": "finished",
       "parent_msg_id": "33986481-8b94-4d53-9363-b088dd893255",
       "queued_time": "2025-07-16T13:06:43.1528503Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download_folder_as_zip(repo_owner, repo_name, output_zip, branch=\"main\", folder_to_extract=\"src\",  remove_folder_prefix = \"\"):\n",
    "    # Construct the URL for the GitHub API to download the repository as a zip file\n",
    "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/zipball/{branch}\"\n",
    "    \n",
    "    # Make a request to the GitHub API\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ensure the directory for the output zip file exists\n",
    "    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n",
    "    \n",
    "    # Create a zip file in memory\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zipf:\n",
    "        with zipfile.ZipFile(output_zip, 'w') as output_zipf:\n",
    "            for file_info in zipf.infolist():\n",
    "                parts = file_info.filename.split('/')\n",
    "                if  re.sub(r'^.*?/', '/', file_info.filename).startswith(folder_to_extract): \n",
    "                    # Extract only the specified folder\n",
    "                    file_data = zipf.read(file_info.filename)\n",
    "                    output_zipf.writestr(('/'.join(parts[1:]).replace(remove_folder_prefix, \"\")), file_data)\n",
    "\n",
    "def uncompress_zip_to_folder(zip_path, extract_to):\n",
    "    # Ensure the directory for extraction exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    # Uncompress all files from the zip into the specified folder\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    # Delete the original zip file\n",
    "    os.remove(zip_path)\n",
    "\n",
    "def download_zip_file(url,output_zip):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Ensure the directory for the output zip file exists\n",
    "    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n",
    "\n",
    "    \n",
    "    with open(output_zip, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "   \n",
    "\n",
    "repo_owner = \"microsoft\"\n",
    "repo_name = \"fabric-toolbox\"\n",
    "branch = \"main\"\n",
    "folder_prefix = \"monitoring/fabric-unified-admin-monitoring\"\n",
    "\n",
    "# download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/src/src.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/src\", remove_folder_prefix = f\"{folder_prefix}/\")\n",
    "# download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/config/config.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/config\" , remove_folder_prefix = folder_prefix)\n",
    "# download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/data/data.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/data\" , remove_folder_prefix = folder_prefix)\n",
    "\n",
    "download_zip_file(url = \"https://aasaliasari.blob.core.windows.net/fca/src.zip?sv=2023-01-03&st=2025-07-16T12%3A50%3A50Z&se=2025-09-30T12%3A50%3A00Z&sr=b&sp=r&sig=3UlvlYQtRABcqV%2FVUa3D4j3MspERYyskcE2EIN6aCuY%3D\",output_zip = \"./builtin/src/src.zip\")\n",
    "download_zip_file(url = \"https://aasaliasari.blob.core.windows.net/fca/config.zip?sv=2023-01-03&st=2025-07-16T12%3A33%3A43Z&se=2025-09-30T12%3A33%3A00Z&sr=b&sp=r&sig=6dKog19Tw%2FUAH8sIf6%2Fflz4jCeS%2BLuvZaO1bYTKHkU8%3D\",output_zip = \"./builtin/config/config.zip\")\n",
    "\n",
    "uncompress_zip_to_folder(zip_path = \"./builtin/config/config.zip\", extract_to= \"./builtin\")\n",
    "# uncompress_zip_to_folder(zip_path = \"./builtin/data/data.zip\", extract_to= \"./builtin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeef159d-0f52-43a1-a895-5c3b293ffc61",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T13:11:20.1594891Z",
       "execution_start_time": "2025-07-16T13:11:19.8361098Z",
       "normalized_state": "finished",
       "parent_msg_id": "4775923c-f21a-4363-8bd6-a3fd90673167",
       "queued_time": "2025-07-16T13:11:19.8352059Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = './builtin/'\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/deployment_order.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        deployment_order = json.load(file)\n",
    "\n",
    "mapping_table=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b4640-8237-433b-ac46-8986531f28ce",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Definition of deployment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bba6a51-107d-4c10-9a41-5cb2a9e07c27",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T13:28:27.8856249Z",
       "execution_start_time": "2025-07-16T13:28:27.5323666Z",
       "normalized_state": "finished",
       "parent_msg_id": "38f69a53-9acd-45e7-935b-d260fcd0f64b",
       "queued_time": "2025-07-16T13:28:27.5310824Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set environment parameters for Fabric CLI\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "os.environ['FAB_TOKEN'] = token\n",
    "os.environ['FAB_TOKEN_ONELAKE'] = token\n",
    "\n",
    "def run_fab_command( command, capture_output: bool = False, silently_continue: bool = False):\n",
    "    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n",
    "    if (not(silently_continue) and (result.returncode > 0 or result.stderr)):\n",
    "       raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result.stderr}'\")    \n",
    "    if (capture_output): \n",
    "        output = result.stdout.strip()\n",
    "        return output\n",
    "\n",
    "def fab_get_id(name):\n",
    "    id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q id\" , capture_output = True, silently_continue= True)\n",
    "    return(id)\n",
    "\n",
    "def get_id_by_name(name):\n",
    "    for it in deployment_order:\n",
    "        if it.get(\"name\") == name:\n",
    "                return it.get(\"id\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def copy_to_tmp(name):\n",
    "    shutil.rmtree(\"./builtin/tmp\",  ignore_errors=True)\n",
    "    path2zip = \"./builtin/src/src.zip\"\n",
    "    with  ZipFile(path2zip) as archive:\n",
    "        for file in archive.namelist():\n",
    "            if file.startswith(f'src/{name}/'):\n",
    "                archive.extract(file, './builtin/tmp')\n",
    "    return(f\"./builtin/tmp/src/{name}\" )\n",
    "\n",
    "\n",
    "def replace_ids_in_folder(folder_path, mapping_table):\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(('.py', '.json', '.pbir', '.platform', '.ipynb', '.tmdl')) and not file_name.endswith('report.json'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    for mapping in mapping_table:  \n",
    "                        content = content.replace(mapping[\"old_id\"], mapping[\"new_id\"])\n",
    "                with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                    file.write(content)\n",
    "\n",
    "def get_semantic_model_id(report_folder):\n",
    "    definition_file = os.path.join(report_folder, 'definition.pbir')\n",
    "    if os.path.exists(definition_file):\n",
    "        with open(definition_file, 'r', encoding='utf-8') as file:\n",
    "            content = json.load(file)\n",
    "            semantic_model_id = content.get('datasetReference', {}).get('byConnection', {}).get('pbiModelDatabaseName')\n",
    "            if semantic_model_id:\n",
    "                return semantic_model_id\n",
    "    return None\n",
    "\n",
    "def update_sm_connection_to_fca_lakehouse(semantic_model_folder):\n",
    "    new_sm_db= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FCA.Lakehouse -q properties.sqlEndpointProperties.connectionString\", capture_output = True, silently_continue=True)\n",
    "    new_lakehouse_sql_id= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FCA.Lakehouse -q properties.sqlEndpointProperties.id\", capture_output = True, silently_continue=True)\n",
    "        \n",
    "    expressions_file = os.path.join(semantic_model_folder, 'definition', 'expressions.tmdl')\n",
    "    if os.path.exists(expressions_file):\n",
    "        with open(expressions_file, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            match = re.search(r'Sql\\.Database\\(\"([^\"]+)\",\\s*\"([^\"]+)\"\\)', content)\n",
    "            if match:\n",
    "                old_sm_db, old_lakehouse_sql_id = match.group(1), match.group(2)\n",
    "                content = content.replace(old_sm_db, new_sm_db).replace(old_lakehouse_sql_id, new_lakehouse_sql_id)\n",
    "                with open(expressions_file, 'w', encoding='utf-8') as file:\n",
    "                    file.write(content)\n",
    "\n",
    "\n",
    "def update_report_definition( path): \n",
    "    semantic_model_id = get_semantic_model_id(path)\n",
    "    definition_path = os.path.join(path, \"definition.pbir\")\n",
    "   \n",
    "    with open(definition_path, \"r\", encoding=\"utf8\") as file:\n",
    "        report_definition = json.load(file)\n",
    "\n",
    "    report_definition[\"datasetReference\"][\"byPath\"] = None\n",
    "\n",
    "    by_connection_obj = {\n",
    "            \"connectionString\": None,\n",
    "            \"pbiServiceModelId\": None,\n",
    "            \"pbiModelVirtualServerName\": \"sobe_wowvirtualserver\",\n",
    "            \"pbiModelDatabaseName\": semantic_model_id,\n",
    "            \"name\": \"EntityDataSource\",\n",
    "            \"connectionType\": \"pbiServiceXmlaStyleLive\",\n",
    "        }\n",
    "\n",
    "    report_definition[\"datasetReference\"][\"byConnection\"] = by_connection_obj\n",
    "\n",
    "    with open(definition_path, \"w\") as file:\n",
    "            json.dump(report_definition, file, indent=4)\n",
    "\n",
    "def print_color(text, state):\n",
    "    red  = '\\033[91m'\n",
    "    yellow = '\\033[93m'  \n",
    "    green = '\\033[92m'   \n",
    "    white = '\\033[0m'  \n",
    "    if state == \"error\":\n",
    "        print(red, text, white)\n",
    "    elif state == \"warning\":\n",
    "        print(yellow, text, white)\n",
    "    elif state == \"success\":\n",
    "        print(green, text, white)\n",
    "    else:\n",
    "        print(\"\", text)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a24f9d-acfc-41a4-ae24-772e5200f74a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Creation of connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473b6db-df34-4a72-bd1a-05d5ddefa78e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get current Workspace\n",
    "This cell gets the current workspace to deploy FCA automatically inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d54542c-1e34-434b-bada-d73fbe7c2535",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T13:11:31.5023195Z",
       "execution_start_time": "2025-07-16T13:11:31.1817248Z",
       "normalized_state": "finished",
       "parent_msg_id": "475295ba-64b2-4901-a6bb-13706e3cdf3c",
       "queued_time": "2025-07-16T13:11:31.1807794Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'old_id': '1afa5fb6-49eb-4aa5-9430-fa0358d6f502',\n",
       "  'new_id': 'd280e534-4d92-4c2d-bbc2-8c49d5b53ac8'},\n",
       " {'old_id': '00000000-0000-0000-0000-000000000000',\n",
       "  'new_id': 'd280e534-4d92-4c2d-bbc2-8c49d5b53ac8'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_workspace_id = fabric.get_notebook_workspace_id()\n",
    "res = run_fab_command(f\"api -X get workspaces/{trg_workspace_id}\" , capture_output = True, silently_continue=True)\n",
    "trg_workspace_name = json.loads(res)[\"text\"][\"displayName\"]\n",
    "\n",
    "print(f\"Current workspace: {trg_workspace_name}\")\n",
    "print(f\"Current workspace ID: {trg_workspace_id}\")\n",
    "\n",
    "\n",
    "mapping_table.append({ \"old_id\": get_id_by_name(\"Focus\"), \"new_id\": trg_workspace_id })\n",
    "mapping_table.append({ \"old_id\": \"00000000-0000-0000-0000-000000000000\", \"new_id\": trg_workspace_id })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8628a42-1d8a-4192-8e75-4754e626fede",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deployment Logic\n",
    "This part iterates through all the items, gets the respective source code, replaces all IDs dynamically and deploys the new item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "315ef8af-ff5a-4323-869c-7198e910c0bf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-07-16T13:16:11.4996726Z",
       "execution_start_time": "2025-07-16T13:14:58.8051885Z",
       "normalized_state": "finished",
       "parent_msg_id": "c2d718fa-ee03-4a0f-9534-02543e203abf",
       "queued_time": "2025-07-16T13:14:58.8042527Z",
       "session_id": "8e32a5d4-da87-4419-b30e-81e23a3a1177",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############################################\n",
      "Deploying FCA.Lakehouse\n",
      "x create: [AlreadyExists] An item with the same name exists\n",
      "\n",
      "#############################################\n",
      "Deploying 01_Load_Focus.Notebook\n",
      "! An item with the same name exists\n",
      "Importing (update) './builtin/tmp/src/01_Load_Focus.Notebook' → '/FCA.Workspace/01_Load_Focus.Notebook'...\n",
      "* '01_Load_Focus.Notebook' imported\n",
      "\n",
      "#############################################\n",
      "Deploying Generate_Calendar_Table.Notebook\n",
      "! An item with the same name exists\n",
      "Importing (update) './builtin/tmp/src/Generate_Calendar_Table.Notebook' → '/FCA.Workspace/Generate_Calendar_Table.Notebook'...\n",
      "* 'Generate_Calendar_Table.Notebook' imported\n",
      "\n",
      "#############################################\n",
      "Deploying Lakehouse_Optimization.Notebook\n",
      "! An item with the same name exists\n",
      "Importing (update) './builtin/tmp/src/Lakehouse_Optimization.Notebook' → '/FCA.Workspace/Lakehouse_Optimization.Notebook'...\n",
      "* 'Lakehouse_Optimization.Notebook' imported\n",
      "\n",
      "#############################################\n",
      "Deploying 01_Load_Meters.Notebook\n",
      "! An item with the same name exists\n",
      "Importing (update) './builtin/tmp/src/01_Load_Meters.Notebook' → '/FCA.Workspace/01_Load_Meters.Notebook'...\n",
      "* '01_Load_Meters.Notebook' imported\n",
      "\n",
      "#############################################\n",
      "Deploying FCA_Core_SM.SemanticModel\n",
      "Importing './builtin/tmp/src/FCA_Core_SM.SemanticModel' → '/FCA.Workspace/FCA_Core_SM.SemanticModel'...\n",
      "* 'FCA_Core_SM.SemanticModel' imported\n",
      "\n",
      "#############################################\n",
      "Deploying FCA_Core_Report.Report\n",
      "Importing './builtin/tmp/src/FCA_Core_Report.Report' → '/FCA.Workspace/FCA_Core_Report.Report'...\n",
      "* 'FCA_Core_Report.Report' imported\n",
      "\n",
      "#############################################\n",
      "Deploying Load Meter.DataPipeline\n",
      "Importing './builtin/tmp/src/Load Meter.DataPipeline' → '/FCA.Workspace/Load Meter.DataPipeline'...\n",
      "* 'Load Meter.DataPipeline' imported\n",
      "\n",
      "#############################################\n",
      "Deploying Load FCA E2E.DataPipeline\n",
      "Importing './builtin/tmp/src/Load FCA E2E.DataPipeline' → '/FCA.Workspace/Load FCA E2E.DataPipeline'...\n",
      "* 'Load FCA E2E.DataPipeline' imported\n"
     ]
    }
   ],
   "source": [
    "exclude = [\"Focus\", 'Deploy_FCA']\n",
    "\n",
    "for it in deployment_order:\n",
    "\n",
    "    new_id = None\n",
    "    \n",
    "    name = it[\"name\"]\n",
    "\n",
    "    if name in exclude:\n",
    "            continue\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"Deploying {name}\")\n",
    "\n",
    "    # Copy and replace IDs in the item\n",
    "    tmp_path = copy_to_tmp(name)\n",
    "    replace_ids_in_folder(tmp_path, mapping_table)\n",
    "\n",
    "    cli_parameter = ''\n",
    "    if \"Notebook\" in name:\n",
    "        cli_parameter = cli_parameter + \" --format .ipynb\"\n",
    "    elif \"Lakehouse\" in name:\n",
    "        run_fab_command(f\"create /{trg_workspace_name}.Workspace/{name}\" , silently_continue=True )\n",
    "        new_id = fab_get_id(name)\n",
    "        mapping_table.append({ \"old_id\": get_id_by_name(name), \"new_id\": new_id })\n",
    "        \n",
    "        continue\n",
    "    elif \"Report\" in name:\n",
    "        update_report_definition(  tmp_path  )\n",
    "    elif \"SemanticModel\" in name:\n",
    "        update_sm_connection_to_fca_lakehouse(tmp_path)\n",
    "    \n",
    "    \n",
    "    run_fab_command(f\"import  /{trg_workspace_name}.Workspace/{name} -i {tmp_path} -f {cli_parameter} \", silently_continue= True)\n",
    "    new_id= fab_get_id(name)\n",
    "    mapping_table.append({ \"old_id\": it[\"id\"], \"new_id\": new_id })\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
